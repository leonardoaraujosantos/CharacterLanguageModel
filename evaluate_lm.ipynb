{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Num classes: 69\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import models\n",
    "import utils_char_lm\n",
    "import utils_char_dataset\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "print('Device:', device)\n",
    "\n",
    "model_path = './model_lm_best.pt'\n",
    "\n",
    "# The codemap is a dictionary of words to class index\n",
    "codemap = utils_char_dataset.load_pickle('./codemap_LM.pickle')\n",
    "\n",
    "num_classes = len(codemap)\n",
    "print('Num classes:', num_classes)\n",
    "\n",
    "# Hyperparameters\n",
    "# Pure sequence to sequence models can't deal with batches\n",
    "hidden_size = 256\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_lm = models.CharLangModel(num_classes, hidden_size, num_classes, num_layers=num_layers)\n",
    "char_lm = char_lm.to(device)\n",
    "\n",
    "checkpoint = torch.load(model_path)\n",
    "char_lm.load_state_dict(checkpoint['seq_model']);\n",
    "char_lm.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Probabilities of sequence of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Thi1):0.000000\n",
      "P(This):0.052008\n",
      "P(Love):0.021699\n",
      "P(BrA):0.000013\n"
     ]
    }
   ],
   "source": [
    "lst_words = ['Thi1', 'This', 'Love', 'BrA']\n",
    "for word in lst_words:\n",
    "    print('P(%s):%f' % (word, utils_char_lm.getProbabilitySentence(word, char_lm, device, codemap)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils_char_lm.getProbabilitySentence('Hello', char_lm, device, codemap) > utils_char_lm.getProbabilitySentence('Hell0', char_lm, device, codemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def prob_sentence(word, model, device, codemap):        \n",
    "    # Convert each character on the word into it's class id\n",
    "    chars_class = [utils_char_dataset.class_id_from_char(char, codemap) for char in word]\n",
    "    print('chars_class:', chars_class)\n",
    "    num_chars = len(chars_class)   \n",
    "    print('num_chars:', num_chars)\n",
    "    curr_batch_size = 1            \n",
    "    model.eval()\n",
    "    scores_lst = []\n",
    "    with torch.no_grad():\n",
    "        # Initialize model on the beginning of the sequence\n",
    "        hidden_state = models.initHidden(curr_batch_size, False, model.hidden_size, model.num_layers, device)\n",
    "        # Iterate on all charactres from word ie: Hello --> [23, 46, 53, 53, 56]\n",
    "        for idx in range(num_chars):\n",
    "            # Convert class word index to a tensor\n",
    "            input = torch.tensor(chars_class[idx]).type(torch.LongTensor).unsqueeze(0).unsqueeze(0).to(device)   \n",
    "            # Push input(character) to the model\n",
    "            # Probabilities shape [1 x 1 x num_classes]\n",
    "            probabilities, hidden_state = model(input, hidden_state, torch.tensor(1).unsqueeze(0))\n",
    "            print('probabilities:', probabilities.shape)\n",
    "            # Get the probability of the next input character given the previous inputs \n",
    "            if idx < num_chars - 1:\n",
    "                print('\\tidx:', idx)\n",
    "                input_next = torch.tensor(chars_class[idx+1]).type(torch.LongTensor).unsqueeze(0).unsqueeze(0).to(device).item()                \n",
    "                probabilities = probabilities.squeeze(0).squeeze(0)    \n",
    "                prob_next = probabilities[input_next].item()\n",
    "                scores_lst.append(prob_next)                   \n",
    "            \n",
    "    # Return the product of the probabilities\n",
    "    return np.prod(scores_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars_class: [23, 46, 53, 53, 56]\n",
      "num_chars: 5\n",
      "probabilities: torch.Size([1, 1, 69])\n",
      "\tidx: 0\n",
      "probabilities: torch.Size([1, 1, 69])\n",
      "\tidx: 1\n",
      "probabilities: torch.Size([1, 1, 69])\n",
      "\tidx: 2\n",
      "probabilities: torch.Size([1, 1, 69])\n",
      "\tidx: 3\n",
      "probabilities: torch.Size([1, 1, 69])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0186739064190997e-07"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_sentence('Hello', char_lm, device, codemap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(t)he<EOS>\n",
      "(k)now<EOS>\n",
      "(de)spise<EOS>\n",
      "(Liv)ed<EOS>\n",
      "(Pre)ferr'd,<EOS>\n",
      "(To be or not to b).<EOS>\n"
     ]
    }
   ],
   "source": [
    "lst_words = ['t', 'k', 'de', 'Liv', 'Pre', 'To be or not to b']\n",
    "for word in lst_words:\n",
    "    pred = utils_char_lm.getNextChar(word,100, char_lm, device, codemap, greedly=False)\n",
    "    res_str = ''.join([utils_char_dataset.char_from_class_id(class_id, codemap) for class_id in pred])\n",
    "    print('('+word+')'+res_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
